# Test Analytics Features

{:toc}

## Find flaky (unreliable) tests

See which tests are most disruptive to continuous deployments via reliability scores and trends on both your entire test suite and individual tests.

<strong>Reliablity</strong> is calculated as follows:

- Test suite reliability = passed_runs / (passed_runs + failed_runs) * 100
- Individual test reliability = passed_test_executions / (passed_test_executions + failed_test_executions) * 100

(Other test execution results, such as `unknown` and `skipped`, are ignored in the test reliability calculation.)

`‚ùóImportant:` In Test Analytics, a run is marked as red/failed as soon as a test execution fails (regardless of whether it passes on a retry) to help surface unreliable tests. You can have a situation where a build eventually passes on retry in a Pipeline, and the related run is marked as red/failed in Test Analytics.

<em><strong>Coming soon:</strong> even more granularity into run states (such as in progress, finished, and information about retries), with web hooks so that you can pull that information into your preferred platform.</em>


## Spot sneaky slow-downs

Find performance degradations, even in parallelized builds. Track down what's slowing down your test runs and individual test executions by viewing trends over time, and then dive deep into individual test execution span timelines to identify patterns.

<%= image "test-trend.png", width: 1175, height: 474, alt: "Screenshot of test trend page showing change in duration across test runs and a recent failed test execution" %>

<%= image "span-timeline.png", width: 1125, height: 451, alt: "Screenshot of span timeline with user-defined annotation" %>

## Track trends across parallelized builds

Test Analytics works even when your test runs are split across agents by de-duplicating against the Test Analyics API token and BUILD_ID environment variable. (If you suspect this isn't working properly, double-check that BUILD_ID is available to any containers running your builds.)

## Set suites that suit your needs

In Test Analytics, a "test suite" is a collection of tests. A run is to a suite what a build is to a Pipeline.

Many organizations set up one suite per test framework (ie, one for RSpec, and another for Jest). Others use a common model, such as JUnit XML, to combine tests from multiple frameworks to set up custom "backend" and "frontend" suites.

Each suite inside Test Analytics has a unique API token that you can use to route test information to the correct suite. Pipelines and test suites do not need to have a one-to-one relationship.

To delete a suite, or regenerate its API token, go to suite settings.

## Compare across branches

You can set one default branch per suite. This allows you to track trends and set monitors against your most important codebase, and compare it to results across all branches.

This default is typically your `main` production branch, but can be any existing branch you choose. To change your default branch, go to suite settings.

<em><strong>Coming soon:</strong> the ability to select more branches via the user interface. If you'd like to see trends for more branches today, type any existing branch name into the branch query parameter in the Test Analytics URL.</em>

